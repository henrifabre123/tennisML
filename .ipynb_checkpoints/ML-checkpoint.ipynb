{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: hand, dtype: int64\n",
      "Index(['name', 'hand', 'height', 'rang', 'matchs', 'win',\n",
      "       'pourc_return_win_pnt', 'pourc_break_games', 'pourc_break_point_made',\n",
      "       'pourc_break_point_saved', 'pourc_serv_games_win', 'pourc_serv_in',\n",
      "       'mean_ranking_oppo', 'pourc_serv_win_pnt', 'Return Rating',\n",
      "       ' % Serve Return Points Won', ' % 2nd Serve Return Points Won',\n",
      "       ' % Return Games Won', ' % Break Points Converted',\n",
      "       'Under Pressure Rating', ' % Break Point Saved',\n",
      "       ' % Break Points Converted Pressure', ' % Deciding Sets Won',\n",
      "       ' % Tie Breaks Won'],\n",
      "      dtype='object')\n",
      "(639, 17)\n",
      "(639,)\n",
      "RMSE: 14.807470586033592\n",
      "RMSE par fold :  [14.86246462 12.8077192  13.35595452 13.64122798 15.48710602]\n",
      "RMSE moyen :  14.030894467351866\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "# Chargement des données\n",
    "base_path = './Data/Data_utiles/Data_ML/'\n",
    "\n",
    "# Liste pour stocker chaque DataFrame\n",
    "dataframes = []\n",
    "\n",
    "# Boucle pour lire chaque fichier CSV de 1995 à 2018\n",
    "for year in range(1995, 2019):\n",
    "    file_path = f'{base_path}infos_joueurs_{year}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concaténer tous les DataFrames en un seul\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "columns = [\n",
    "    \"name\", \"hand\", \"height\", \"rang\", \"matchs\", \"win\", \n",
    "    \"pourc_return_win_pnt\", \"pourc_break_games\", \"pourc_break_point_made\", \n",
    "    \"pourc_break_point_saved\", \"pourc_serv_games_win\", \"pourc_serv_in\", \n",
    "    \"mean_ranking_oppo\", \"pourc_serv_win_pnt\", \"Return Rating\", \n",
    "    \" % Serve Return Points Won\", \" % 2nd Serve Return Points Won\", \n",
    "    \" % Return Games Won\", \" % Break Points Converted\", \"Under Pressure Rating\", \n",
    "    \" % Break Point Saved\", \" % Break Points Converted Pressure\", \n",
    "    \" % Deciding Sets Won\", \" % Tie Breaks Won\"\n",
    "]\n",
    " # Complétez avec les autres noms de colonnes\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df['hand'] = df['hand'].map({'R': 1, 'L': 0})\n",
    "\n",
    "# Vérifier les modifications\n",
    "print(df['hand'].head())\n",
    "print(df.columns)\n",
    "# Mise à jour des caractéristiques en excluant les colonnes spécifiées\n",
    "\n",
    "\n",
    "# Séparation des caractéristiques et des étiquettes\n",
    "features = df.drop(['name','rang','Under Pressure Rating', ' % Break Point Saved', \n",
    "    ' % Break Points Converted Pressure', ' % Deciding Sets Won', \n",
    "    ' % Tie Breaks Won'], axis=1)\n",
    "labels = df['rang']\n",
    "  # Affiche les premières lignes pour vérifier les données\n",
    "indices_with_nan = features[features.isna().any(axis=1)].index\n",
    "\n",
    "# Supprimer ces lignes de features\n",
    "features_clean = features.dropna()\n",
    "\n",
    "# Supprimer les mêmes lignes de labels\n",
    "labels_clean = labels.drop(indices_with_nan) # Affiche la taille de l'ensemble des étiquettes\n",
    "print(features_clean.shape)  # Doit montrer (N, nombre_de_colonnes)\n",
    "print(labels_clean.shape) \n",
    "# Prétraitement : Encodage one-hot pour les variables catégorielles et normalisation pour les numériques\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['hand']),\n",
    "        ('num', StandardScaler(), features.columns.drop('hand'))\n",
    "    ])\n",
    "\n",
    "# Pipeline : Prétraitement + modèle\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_clean, labels_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vérification et suppression des NaN dans les ensembles d'entraînement et de test\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]  # Assurez-vous que les indices correspondent\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation du modèle\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "#réalisation de cross validation\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Utilisation de KFold pour un contrôle plus précis\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Évaluation du modèle en utilisant la cross-validation avec le pipeline\n",
    "scores = cross_val_score(model, features_clean, labels_clean, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(\"RMSE par fold : \", rmse_scores)\n",
    "print(\"RMSE moyen : \", rmse_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      hand  height  matchs   win  pourc_return_win_pnt  pourc_break_games  \\\n",
      "0        1   196.0    62.0  39.0              0.361919           0.207784   \n",
      "1        1   190.0    83.0  62.0              0.425043           0.348266   \n",
      "2        1   188.0    42.0  18.0              0.346259           0.179832   \n",
      "3        1   178.0    53.0  32.0              0.388201           0.245503   \n",
      "4        1   193.0    51.0  28.0              0.377143           0.236942   \n",
      "...    ...     ...     ...   ...                   ...                ...   \n",
      "3123     1   196.0    37.0  18.0              0.336723           0.155910   \n",
      "3124     0   188.0    35.0  18.0              0.382003           0.266190   \n",
      "3125     1   183.0    50.0  28.0              0.383998           0.245907   \n",
      "3128     1   178.0    19.0   7.0              0.331022           0.165849   \n",
      "3129     1   196.0    14.0   4.0              0.334671           0.147740   \n",
      "\n",
      "      pourc_break_point_made  pourc_break_point_saved  pourc_serv_games_win  \\\n",
      "0                   0.380872                 0.637572              0.847660   \n",
      "1                   0.458746                 0.537731              0.817264   \n",
      "2                   0.301581                 0.543701              0.797039   \n",
      "3                   0.419419                 0.574493              0.769957   \n",
      "4                   0.424395                 0.566097              0.815757   \n",
      "...                      ...                      ...                   ...   \n",
      "3123                0.363663                 0.574230              0.826617   \n",
      "3124                0.403053                 0.608979              0.821499   \n",
      "3125                0.371245                 0.621861              0.792925   \n",
      "3128                0.364429                 0.568237              0.770048   \n",
      "3129                0.299972                 0.624493              0.746704   \n",
      "\n",
      "      pourc_serv_in  mean_ranking_oppo  pourc_serv_win_pnt  Return Rating  \\\n",
      "0          0.589139         108.016129            0.674162          133.9   \n",
      "1          0.557247          70.228916            0.659948          162.5   \n",
      "2          0.594829         125.500000            0.639972          121.1   \n",
      "3          0.573847          64.452830            0.615109          143.7   \n",
      "4          0.654439          92.294118            0.659092          141.3   \n",
      "...             ...                ...                 ...            ...   \n",
      "3123       0.622636          64.162162            0.663901          120.0   \n",
      "3124       0.645400         103.800000            0.643622          139.0   \n",
      "3125       0.613520          64.200000            0.633826          143.4   \n",
      "3128       0.648252          87.210526            0.620429          132.8   \n",
      "3129       0.627246          91.214286            0.621103          126.1   \n",
      "\n",
      "       % Serve Return Points Won   % 2nd Serve Return Points Won  \\\n",
      "0                          0.266                           0.506   \n",
      "1                          0.316                           0.554   \n",
      "2                          0.253                           0.479   \n",
      "3                          0.301                           0.508   \n",
      "4                          0.280                           0.516   \n",
      "...                          ...                             ...   \n",
      "3123                       0.271                           0.458   \n",
      "3124                       0.292                           0.480   \n",
      "3125                       0.277                           0.533   \n",
      "3128                       0.254                           0.489   \n",
      "3129                       0.275                           0.454   \n",
      "\n",
      "       % Return Games Won   % Break Points Converted  \n",
      "0                   0.199                      0.368  \n",
      "1                   0.322                      0.433  \n",
      "2                   0.169                      0.310  \n",
      "3                   0.242                      0.386  \n",
      "4                   0.225                      0.392  \n",
      "...                   ...                        ...  \n",
      "3123                0.154                      0.317  \n",
      "3124                0.211                      0.407  \n",
      "3125                0.238                      0.386  \n",
      "3128                0.168                      0.417  \n",
      "3129                0.173                      0.359  \n",
      "\n",
      "[639 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième modèle de ML :GradientBoostingRegressor\n",
    "GradientBoostingRegressor est un modèle puissant qui construit des arbres de décision de manière séquentielle, où chaque arbre tente de corriger les erreurs des arbres précédents. Voici un exemple de code utilisant GradientBoostingRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE sur l'ensemble de test : 13.83982480044501\n",
      "RMSE par fold : [13.8398248  13.25627024 13.39855893 14.40236881 14.58997891]\n",
      "RMSE moyen : 13.89740033870961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Prétraitement : Encodage one-hot pour les variables catégorielles et normalisation pour les numériques\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['hand']),  # Assurez-vous que 'hand' est la colonne catégorielle\n",
    "        ('num', StandardScaler(), features_clean.select_dtypes(include=['float64', 'int64']).columns)\n",
    "    ])\n",
    "\n",
    "# Création du pipeline avec GradientBoostingRegressor\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_clean, labels_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation du modèle sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE sur l'ensemble de test :\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# Réalisation de la cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, features_clean, labels_clean, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(\"RMSE par fold :\", rmse_scores)\n",
    "print(\"RMSE moyen :\", rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Meilleurs paramètres :  {'regressor__learning_rate': 0.01, 'regressor__max_depth': 3, 'regressor__n_estimators': 300}\n",
      "RMSE sur l'ensemble de test : 13.926325636250269\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Création du pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Paramètres pour la recherche en grille\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'regressor__max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Recherche en grille avec validation croisée\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(features_clean, labels_clean)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Afficher les meilleurs paramètres\n",
    "print(\"Meilleurs paramètres : \", grid_search.best_params_)\n",
    "\n",
    "# Évaluation du modèle\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_clean, labels_clean, test_size=0.2, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE sur l'ensemble de test :\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19901231', '19911230', '19921228', '19931227', '19941226', '19951225', '19961230', '19971229', '19981228', '19991227', '20001225', '20011231', '20021230', '20031229', '20041227', '20051226', '20061225', '20071231', '20081229', '20091228', '20101227', '20111226', '20121231', '20131230', '20141229', '20151228', '20161226', '20171225', '20181231', '20191230', '20201228', '20211227', '20221226']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Exemple de données\n",
    "data = pd.read_csv('./Data/Data_utiles/info_rank.csv')['ranking_date']\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convertir les dates en format datetime\n",
    "\n",
    "\n",
    "\n",
    "df['ranking_date'] = pd.to_datetime(df['ranking_date'], format='%Y%m%d')\n",
    "\n",
    "# Trier les dates\n",
    "df = df.sort_values(by='ranking_date')\n",
    "\n",
    "# Extraire la dernière date de chaque année\n",
    "last_dates = df.groupby(df['ranking_date'].dt.year)['ranking_date'].last()\n",
    "\n",
    "# Convertir les dates dans le format d'origine (AAAAMMJJ)\n",
    "formatted_dates = [date.strftime('%Y%m%d') for date in last_dates]\n",
    "\n",
    "print(formatted_dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
